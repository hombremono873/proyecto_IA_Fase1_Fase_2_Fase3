{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto de Inteligencia Artificial  \n",
        "**Tema:** Predictor en Actividades Bancarias  \n",
        "\n",
        "**Asignatura:** Técnicas en Inteligencia Artificial  \n",
        "**Docente:** Raúl Ramos Pollán, Jonathan Granda  \n",
        "**Fecha:** 21-08-2025  \n",
        "\n",
        "---\n",
        "\n",
        "## Fuente del Conjunto de Datos  \n",
        "\n",
        "**Competencia:** [Binary Classification with a Bank Dataset](https://www.kaggle.com/competitions/playground-series-s5e8/overview)  \n",
        "**Plataforma:** Kaggle – *Tabular Playground Series*  \n",
        "\n",
        "**Ruta a los datos**\n",
        "https://www.kaggle.com/competitions/playground-series-s5e8/data\n",
        "## Objetivo del Banco\n",
        "\n",
        "Predecir si un cliente **aceptará un depósito a plazo** (y=1) tras una campaña de marketing.  \n",
        "Con esta predicción el banco puede **priorizar a quién contactar**, **reducir costos de campaña** y **mejorar la tasa de conversión** evitando llamadas innecesarias.\n",
        "\n",
        "## Qué hace este notebook\n",
        "- Carga `train.csv` y `test.csv`.\n",
        "- Limpia y codifica variables (mismo tratamiento para train y test).\n",
        "- Entrena un **RandomForest** y evalúa (Accuracy, ROC-AUC, PR-AUC, reporte de clasificación).\n",
        "- Genera `submission.csv` con columnas **`id,y`**.\n"
      ],
      "metadata": {
        "id": "cx8fcFDaCKtg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Descarga de librerías\n",
        "**python**"
      ],
      "metadata": {
        "id": "KPHTL0apE5Tk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "fXt41s8-Blem"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "from google.colab import files\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    classification_report\n",
        ")\n",
        "import joblib\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalar kaggle para poder acceder directamente a los archivos train.csv y test.csv"
      ],
      "metadata": {
        "id": "zIc6MvSY8UUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "XY3rN3Ke3nQc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar json\n",
        "El profesor debe tener previamente un token de acceso, acceptar previamente la competencia"
      ],
      "metadata": {
        "id": "iybJuvWI9C58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"➡️ Selecciona tu archivo kaggle.json\")\n",
        "files.upload()  # Aquí escoges kaggle.json desde tu PC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "wNoDLFwT3uSa",
        "outputId": "a613845a-a9de-46de-9d42-6b173d3b8668"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "➡️ Selecciona tu archivo kaggle.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-210458ad-d110-46d0-a941-28336e35c034\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-210458ad-d110-46d0-a941-28336e35c034\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (1).json': b'{\"username\":\"omaralbertotorres\",\"key\":\"5eccf955249f562d3b538f9334abdbf8\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "bFoH1zBU33G5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Descarga de los datos"
      ],
      "metadata": {
        "id": "EenXUbrS9ZWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./datos\n",
        "!kaggle competitions download -c playground-series-s5e8 -p ./datos\n",
        "!unzip -o ./datos/*.zip -d ./datos\n",
        "!ls -lh ./datos\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev-aMmYN4Jkr",
        "outputId": "13263c9b-2134-4c21-9093-70fc85bd2d64"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playground-series-s5e8.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  ./datos/playground-series-s5e8.zip\n",
            "  inflating: ./datos/sample_submission.csv  \n",
            "  inflating: ./datos/test.csv        \n",
            "  inflating: ./datos/train.csv       \n",
            "total 101M\n",
            "-rw-r--r-- 1 root root  15M Jul  5 02:11 playground-series-s5e8.zip\n",
            "-rw-r--r-- 1 root root 2.7M Jul  5 02:11 sample_submission.csv\n",
            "-rw-r--r-- 1 root root  21M Jul  5 02:11 test.csv\n",
            "-rw-r--r-- 1 root root  63M Jul  5 02:11 train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lectura de los datos"
      ],
      "metadata": {
        "id": "wAh8-iLddRLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------------------\n",
        "# El código lee los archivos *.csv cargados en el paso previo\n",
        "# Se construye los datasets para entrenamiento y prueba\n",
        "#--------------------------------------------------------------\n",
        "train = pd.read_csv(\"./datos/train.csv\")\n",
        "test  = pd.read_csv(\"./datos/test.csv\")\n",
        "sample = pd.read_csv(\"./datos/sample_submission.csv\")\n",
        "\n",
        "print(\"Train:\", train.shape)\n",
        "print(\"Test :\", test.shape)\n",
        "print(\"Sample submission:\", sample.shape)\n",
        "\n",
        "print(\"\\nColumnas de TRAIN:\", train.columns.tolist())\n",
        "print(\"Columnas de TEST :\", test.columns.tolist())\n",
        "print(\"Primeras filas de TRAIN:\")\n",
        "print(train.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBTXBl2W4PG_",
        "outputId": "1c67a228-862f-4d30-86db-509c4bac4ea1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (750000, 18)\n",
            "Test : (250000, 17)\n",
            "Sample submission: (250000, 2)\n",
            "\n",
            "Columnas de TRAIN: ['id', 'age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
            "Columnas de TEST : ['id', 'age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
            "Primeras filas de TRAIN:\n",
            "   id  age          job  marital  education default  balance housing loan  \\\n",
            "0   0   42   technician  married  secondary      no        7      no   no   \n",
            "1   1   38  blue-collar  married  secondary      no      514      no   no   \n",
            "2   2   36  blue-collar  married  secondary      no      602     yes   no   \n",
            "3   3   27      student   single  secondary      no       34     yes   no   \n",
            "4   4   26   technician  married  secondary      no      889     yes   no   \n",
            "\n",
            "    contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
            "0  cellular   25   aug       117         3     -1         0  unknown  0  \n",
            "1   unknown   18   jun       185         1     -1         0  unknown  0  \n",
            "2   unknown   14   may       111         2     -1         0  unknown  0  \n",
            "3   unknown   28   may        10         2     -1         0  unknown  0  \n",
            "4  cellular    3   feb       902         1     -1         0  unknown  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# En este punto tenemos los archivos train.csv y test.csv"
      ],
      "metadata": {
        "id": "gYufO4CC9hhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# Funciones auxiliares para exploración inicial de datos\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def ver_dimensiones(df: pd.DataFrame):\n",
        "    \"\"\"Muestra número de filas y columnas.\"\"\"\n",
        "    return df.shape\n",
        "\n",
        "def ver_columnas(df: pd.DataFrame):\n",
        "    \"\"\"Devuelve la lista de columnas.\"\"\"\n",
        "    return df.columns.tolist()\n",
        "\n",
        "def ver_tipos(df: pd.DataFrame):\n",
        "    \"\"\"Devuelve el tipo de dato de cada columna.\"\"\"\n",
        "    return df.dtypes\n",
        "\n",
        "def ver_nulos(df: pd.DataFrame):\n",
        "    \"\"\"Cuenta valores nulos por columna.\"\"\"\n",
        "    return df.isnull().sum()\n",
        "\n",
        "def ver_estadisticas(df: pd.DataFrame):\n",
        "    \"\"\"Muestra estadísticas básicas (solo numéricas).\"\"\"\n",
        "    return df.describe()\n",
        "\n",
        "def load_dataset(path: str) -> pd.DataFrame:\n",
        "    #return pd.read_excel(path, engine=\"openpyxl\")\n",
        "    return pd.read_csv(\"train.csv\", sep=',')\n"
      ],
      "metadata": {
        "id": "nRfeXvoWV-pF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploración de Datos – Paso 1\n",
        "\n",
        "En este primer paso realizamos una **exploración inicial de los datos**"
      ],
      "metadata": {
        "id": "ek4FvGQKWxSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# Exploración Inicial del Dataset\n",
        "# Se imprimen propiedades clave del DataFrame:\n",
        "# - Dimensiones\n",
        "# - Columnas\n",
        "# - Tipos de datos\n",
        "# - Valores nulos\n",
        "# - Estadísticas descriptivas\n",
        "# ---------------------------------------------\n",
        "def explorar_antes_cleaner_df(df: pd.DataFrame) -> None:\n",
        "  print(\"\\nInformación del dataset antes del procesamiento\\n\")\n",
        "  print(f\"Dimensiones del df: {ver_dimensiones(df)}\")\n",
        "  print(f\"Columnas del df: {ver_columnas(df)}\")\n",
        "  print(f\"Tipos de datos del df: {ver_tipos(df)}\")\n",
        "  print(f\"Valores nulos del df: {ver_nulos(df)}\")\n",
        "  print(f\"Estadísticas básicas del df: {ver_estadisticas(df)}\")\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "xhGuhT_8LeCy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------------------------\n",
        "# Limpieza del Dataset\n",
        "# Esta función elimina columnas irrelevantes o problemáticas:\n",
        "# - id: identificador único\n",
        "# - day, month: variables temporales que pueden inducir ruido\n",
        "# - duration: fuertemente correlacionada con 'y' (puede inducir fuga de datos)\n",
        "#\n",
        "# Parámetros:\n",
        "# - df (pd.DataFrame): conjunto de datos a limpiar\n",
        "# - cols_drop (list): columnas a eliminar\n",
        "# - has_target (bool): True si el DataFrame incluye la columna 'y'\n",
        "#\n",
        "# Retorna:\n",
        "# - Si flag = True: retorna (X, y)\n",
        "# - Si flag = False: retorna solo X\n",
        "# -------------------------------------------------------------------------------------------\n",
        "\n",
        "def clean_df(df: pd.DataFrame, cols_drop: list, flag: bool):\n",
        "    df_clean = df.drop(columns=cols_drop, errors=\"ignore\")\n",
        "\n",
        "    if flag:\n",
        "        y = df_clean[\"y\"]\n",
        "        X = df_clean.drop(columns=[\"y\"], errors=\"ignore\") #Elimina columna\n",
        "        return X, y\n",
        "    else:\n",
        "        return df_clean  # no hay 'y' en test.csv   #Limpieza del test.csv\n",
        "\n"
      ],
      "metadata": {
        "id": "bHilRACkbTyj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# Verificación del Dataset Procesado\n",
        "# Se muestran:\n",
        "# - Confirmación de limpieza\n",
        "# - Dimensiones de X (features)\n",
        "# - Dimensiones de y (target)\n",
        "# - Primeras filas de X para inspección visual\n",
        "# ---------------------------------------------\n",
        "def dataset_cleaner(X: pd.DataFrame, y: pd.DataFrame) ->None:\n",
        "   print(\"Dataset despues de limpiado\\n\")\n",
        "   print(\"✅ Dataset limpio creado\")\n",
        "   print(\"Dimensiones de X:\", X.shape)\n",
        "   print(\"Dimensiones de y:\", y.shape)\n",
        "   print(X.head())\n"
      ],
      "metadata": {
        "id": "6sjwxD5mTyK-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------\n",
        "# Codificación Categórica\n",
        "# Transforma columnas categóricas (tipo object)\n",
        "# en valores numéricos utilizando LabelEncoder.\n",
        "#\n",
        "#  Requiere que train y test tengan las mismas columnas y categorías.\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def encode_categoricals(X):\n",
        "    X_encoded = X.copy()\n",
        "    for col in X_encoded.select_dtypes(include=[\"object\"]).columns:\n",
        "        le = LabelEncoder()\n",
        "        X_encoded[col] = le.fit_transform(X_encoded[col])\n",
        "    return X_encoded\n"
      ],
      "metadata": {
        "id": "Ol1SozVYfzBt"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# División de los Datos\n",
        "\n",
        "En este paso separamos el dataset en **conjunto de entrenamiento (80%)** y  \n",
        "**conjunto de validación (20%)**, asegurando que la proporción de clases en la  \n",
        "variable objetivo se mantenga constante mediante la opción *stratify*.  \n",
        "\n",
        "De esta forma, el modelo se entrena con una parte de los datos y se evalúa con  \n",
        "otra parte independiente, evitando el sobreajuste y permitiendo medir su capacidad de generalización.\n"
      ],
      "metadata": {
        "id": "XJUsVKpchAJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------\n",
        "#  Verificación de Dimensiones\n",
        "# ----------------------------------------\n",
        "import pandas as pd\n",
        "\n",
        "def mostrar_dimensiones_dataset(\n",
        "    X_train: pd.DataFrame,\n",
        "    X_val: pd.DataFrame,\n",
        "    y_train: pd.Series,\n",
        "    y_val: pd.Series\n",
        ") -> None:\n",
        "    print(\"Tamaño de X_train:\", X_train.shape)\n",
        "    print(\"Tamaño de X_val:\", X_val.shape)\n",
        "    print(\"Tamaño de y_train:\", y_train.shape)\n",
        "    print(\"Tamaño de y_val:\", y_val.shape)\n"
      ],
      "metadata": {
        "id": "ACtkMhWQa8ok"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento del Modelo Random Forest\n",
        "\n",
        "Se configuró un `RandomForestClassifier` con los siguientes parámetros:\n",
        "\n",
        "- **n_estimators=300** : número de árboles en el bosque  \n",
        "- **max_depth=20** : profundidad máxima de cada árbol  \n",
        "- **n_jobs=-1** : utiliza todos los núcleos disponibles  \n",
        "- **random_state=42** : asegura reproducibilidad  \n",
        "- **class_weight=\"balanced\"** : ajusta pesos para manejar clases desbalanceadas  \n",
        "- **min_samples_leaf=10** : tamaño mínimo de muestras en una hoja  \n",
        "- **bootstrap=True** : usa muestreo bootstrap para entrenar cada árbol  \n",
        "- **max_samples=0.7** : cada árbol entrena con el 70% de los datos  \n",
        "- **oob_score=True** : calcula desempeño con muestras fuera de bolsa  \n"
      ],
      "metadata": {
        "id": "z2qgT0Jzejft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## -----------------------------------------------------------------------------\n",
        "#  Entrenamiento del Modelo Random Forest\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def modelo_random_forest(X_train, y_train, X_val):\n",
        "    modelo = RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=20,\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        class_weight=\"balanced_subsample\",\n",
        "        min_samples_leaf=20,\n",
        "        min_samples_split=10,\n",
        "        bootstrap=True,\n",
        "        max_samples=0.7,\n",
        "        oob_score=True\n",
        "    )\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred  = modelo.predict(X_val)\n",
        "    y_proba = modelo.predict_proba(X_val)[:, 1]\n",
        "    return modelo, y_pred, y_proba\n"
      ],
      "metadata": {
        "id": "-mLDc5mahzSh"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------------\n",
        "# Evaluación del Modelo en Validación\n",
        "# Se calculan las métricas principales:\n",
        "# - Accuracy , proporción de aciertos globales\n",
        "# - ROC-AUC , capacidad de discriminación entre clases\n",
        "# - PR-AUC , área bajo la curva precisión-recall (importante en desbalance)\n",
        "# - Classification Report , precisión, recall y F1-score por clase\n",
        "# ----------------------------------------------------------------------------\n",
        "def mostrar_resultados(\n",
        "    y_val:pd.DataFrame,\n",
        "    y_pred:pd.DataFrame,\n",
        "    y_proba:pd.DataFrame,\n",
        "    ) -> pd.DataFrame:\n",
        "   print(\"Resultados de la predicción\\n\")\n",
        "   print(\"VAL Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "   print(\"VAL ROC-AUC:\", roc_auc_score(y_val, y_proba))\n",
        "   print(\"VAL PR-AUC:\", average_precision_score(y_val, y_proba))\n",
        "   print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "lkIfXojwdXlh"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Se realiza la predicción con datos del\n",
        "# archivo test.csv\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def predict_datos_test(modelo,X_test_num):\n",
        "  y_pred  = modelo.predict(X_test_num)\n",
        "  y_proba = modelo.predict_proba(X_test_num)[:, 1]\n",
        "  return y_pred, y_proba"
      ],
      "metadata": {
        "id": "f-1H6SiYfUUU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Generación de archivo de envío para Kaggle\n",
        "# Se construye el submission.csv con:\n",
        "# - id,  columna original del test.csv\n",
        "# - y,   predicciones del modelo (0/1)\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def generar_submission(y_pred, ids, ruta_salida=\"sample_submission.csv\"):\n",
        "    submission = pd.DataFrame({\"id\": ids, \"y\": y_pred})\n",
        "    submission.to_csv(ruta_salida, index=False)\n",
        "    files.download(ruta_salida)\n",
        "    return submission\n"
      ],
      "metadata": {
        "id": "mPMCrAydgXak"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "#\n",
        "#    Divide X e y en conjuntos de entrenamiento y validación,\n",
        "#    manteniendo la proporción de clases (stratify=y).\n",
        "\n",
        "#    Parámetros\n",
        "#\n",
        "#    X : Variables independientes\n",
        "#    y : Variable objetivo\n",
        "#    test_size : float (default=0.2), Proporción para validación\n",
        "#    random_state : int (default=42), Semilla para reproducibilidad\n",
        "#    Retorna\n",
        "#    X_train, X_val, y_train, y_val\n",
        "# ------------------------------------------------------------------------------\n",
        "def split_data(X, y, test_size=0.2, random_state=42):\n",
        "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)"
      ],
      "metadata": {
        "id": "4mQu052iavbR"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exportar modelo"
      ],
      "metadata": {
        "id": "tJ6vidfFjwiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Funcion para descargar modelo entrenado\n",
        "# ------------------------------------------------------------------------------\n",
        "def save_model(modelo):\n",
        "    filename = \"modelo_entrenado.pkl\"\n",
        "    joblib.dump(modelo, filename)\n",
        "    files.download(filename)\n",
        "    print(f\"Modelo guardado y descargado como '{filename}'\")\n"
      ],
      "metadata": {
        "id": "v77yGdHHSLDX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Funcion para construir lista de objetos json para pruebas\n",
        "# ------------------------------------------------------------------------------\n",
        "def construir_json_desde_csv(df, n=100, columnas_excluir=None):\n",
        "    if columnas_excluir:\n",
        "        columnas_a_eliminar = [col for col in columnas_excluir if col in df.columns]\n",
        "        df = df.drop(columns=columnas_a_eliminar)\n",
        "    muestras = df.sample(n=n, random_state=42)\n",
        "    return [{\"data\": row.to_dict()} for _, row in muestras.iterrows()]\n",
        "\n"
      ],
      "metadata": {
        "id": "OoT9NxV5p3HR"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "#  Programa principal\n",
        "# ------------------------------------------------------------------------------\n",
        "def main():\n",
        "    df = train\n",
        "    df_test = test\n",
        "\n",
        "    ids = df_test[\"id\"]    # Guardar IDs para el submission\n",
        "\n",
        "    # Columnas a eliminar\n",
        "    cols_drop = [\"id\", \"day\", \"month\", \"duration\"]\n",
        "\n",
        "    # Exploración inicial del dataset\n",
        "    explorar_antes_cleaner_df(df)\n",
        "\n",
        "    # Preprocesamiento\n",
        "    X, y        = clean_df(df, cols_drop, flag=True)\n",
        "    X_test      = clean_df(df_test, cols_drop, flag=False)\n",
        "    X_num       = encode_categoricals(X)\n",
        "    X_test_num  = encode_categoricals(X_test)\n",
        "\n",
        "    # Dataset de entrenamiento limpio\n",
        "    dataset_cleaner(X_num, y)\n",
        "\n",
        "    # División train/val\n",
        "    X_train, X_val, y_train, y_val = split_data(X_num, y)\n",
        "\n",
        "    # Entrenar y validar\n",
        "    modelo, y_pred_val, y_proba_val = modelo_random_forest(X_train, y_train, X_val)\n",
        "\n",
        "    # Mostrar resultados\n",
        "    mostrar_resultados(y_val, y_pred_val, y_proba_val)\n",
        "\n",
        "    # Predicción en test y submission\n",
        "    y_pred_test, y_proba = predict_datos_test(modelo, X_test_num)\n",
        "    generar_submission(y_pred_test, ids, ruta_salida=\"sample_submission.csv\")\n",
        "\n",
        "    return modelo, X_test\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    modelo, X_test = main()\n",
        "    save_model(modelo)\n",
        "    print(X_test.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-jN08pVWm7vA",
        "outputId": "c00f02fc-f6b0-4da4-d061-f74d09322daa"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Información del dataset antes del procesamiento\n",
            "\n",
            "Dimensiones del df: (750000, 18)\n",
            "Columnas del df: ['id', 'age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
            "Tipos de datos del df: id            int64\n",
            "age           int64\n",
            "job          object\n",
            "marital      object\n",
            "education    object\n",
            "default      object\n",
            "balance       int64\n",
            "housing      object\n",
            "loan         object\n",
            "contact      object\n",
            "day           int64\n",
            "month        object\n",
            "duration      int64\n",
            "campaign      int64\n",
            "pdays         int64\n",
            "previous      int64\n",
            "poutcome     object\n",
            "y             int64\n",
            "dtype: object\n",
            "Valores nulos del df: id           0\n",
            "age          0\n",
            "job          0\n",
            "marital      0\n",
            "education    0\n",
            "default      0\n",
            "balance      0\n",
            "housing      0\n",
            "loan         0\n",
            "contact      0\n",
            "day          0\n",
            "month        0\n",
            "duration     0\n",
            "campaign     0\n",
            "pdays        0\n",
            "previous     0\n",
            "poutcome     0\n",
            "y            0\n",
            "dtype: int64\n",
            "Estadísticas básicas del df:                   id            age        balance            day  \\\n",
            "count  750000.000000  750000.000000  750000.000000  750000.000000   \n",
            "mean   374999.500000      40.926395    1204.067397      16.117209   \n",
            "std    216506.495284      10.098829    2836.096759       8.250832   \n",
            "min         0.000000      18.000000   -8019.000000       1.000000   \n",
            "25%    187499.750000      33.000000       0.000000       9.000000   \n",
            "50%    374999.500000      39.000000     634.000000      17.000000   \n",
            "75%    562499.250000      48.000000    1390.000000      21.000000   \n",
            "max    749999.000000      95.000000   99717.000000      31.000000   \n",
            "\n",
            "            duration       campaign          pdays       previous  \\\n",
            "count  750000.000000  750000.000000  750000.000000  750000.000000   \n",
            "mean      256.229144       2.577008      22.412733       0.298545   \n",
            "std       272.555662       2.718514      77.319998       1.335926   \n",
            "min         1.000000       1.000000      -1.000000       0.000000   \n",
            "25%        91.000000       1.000000      -1.000000       0.000000   \n",
            "50%       133.000000       2.000000      -1.000000       0.000000   \n",
            "75%       361.000000       3.000000      -1.000000       0.000000   \n",
            "max      4918.000000      63.000000     871.000000     200.000000   \n",
            "\n",
            "                   y  \n",
            "count  750000.000000  \n",
            "mean        0.120651  \n",
            "std         0.325721  \n",
            "min         0.000000  \n",
            "25%         0.000000  \n",
            "50%         0.000000  \n",
            "75%         0.000000  \n",
            "max         1.000000  \n",
            "\n",
            "\n",
            "Dataset despues de limpiado\n",
            "\n",
            "✅ Dataset limpio creado\n",
            "Dimensiones de X: (750000, 13)\n",
            "Dimensiones de y: (750000,)\n",
            "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
            "0   42    9        1          1        0        7        0     0        0   \n",
            "1   38    1        1          1        0      514        0     0        2   \n",
            "2   36    1        1          1        0      602        1     0        2   \n",
            "3   27    8        2          1        0       34        1     0        2   \n",
            "4   26    9        1          1        0      889        1     0        0   \n",
            "\n",
            "   campaign  pdays  previous  poutcome  \n",
            "0         3     -1         0         3  \n",
            "1         1     -1         0         3  \n",
            "2         2     -1         0         3  \n",
            "3         2     -1         0         3  \n",
            "4         1     -1         0         3  \n",
            "Resultados de la predicción\n",
            "\n",
            "VAL Accuracy: 0.77142\n",
            "VAL ROC-AUC: 0.8189940626896505\n",
            "VAL PR-AUC: 0.47412350559881294\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.78      0.86    131902\n",
            "           1       0.30      0.69      0.42     18098\n",
            "\n",
            "    accuracy                           0.77    150000\n",
            "   macro avg       0.63      0.74      0.64    150000\n",
            "weighted avg       0.87      0.77      0.80    150000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1bd3fdb6-b952-4114-bb53-67a346a243db\", \"sample_submission.csv\", 2250005)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2147bc46-12d2-4724-b797-0e37c6a0303d\", \"modelo_entrenado.pkl\", 189499878)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado y descargado como 'modelo_entrenado.pkl'\n",
            "   age            job  marital  education default  balance housing loan  \\\n",
            "0   32    blue-collar  married  secondary      no     1397     yes   no   \n",
            "1   44     management  married   tertiary      no       23     yes   no   \n",
            "2   36  self-employed  married    primary      no       46     yes  yes   \n",
            "3   58    blue-collar  married  secondary      no    -1380     yes  yes   \n",
            "4   28     technician   single  secondary      no     1950     yes   no   \n",
            "\n",
            "    contact  campaign  pdays  previous poutcome  \n",
            "0   unknown         1     -1         0  unknown  \n",
            "1  cellular         2     -1         0  unknown  \n",
            "2  cellular         2     -1         0  unknown  \n",
            "3   unknown         1     -1         0  unknown  \n",
            "4  cellular         1     -1         0  unknown  \n"
          ]
        }
      ]
    }
  ]
}